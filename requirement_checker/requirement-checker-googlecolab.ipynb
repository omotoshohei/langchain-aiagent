{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9je1hsjIfC0iZjDF35xMv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UL2WWRHozrqC","executionInfo":{"status":"ok","timestamp":1735088463191,"user_tz":-540,"elapsed":22448,"user":{"displayName":"Shohei O","userId":"12040440607234237913"}},"outputId":"74aeaa16-c4e3-4ce6-d16e-fd6337762efa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain==0.3.0\n","  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting langchain-openai==0.2.0\n","  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting langgraph==0.2.22\n","  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (3.11.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (4.0.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (0.3.25)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (0.3.3)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.0)\n","  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (2.10.3)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.3.0) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.0)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.2.0) (1.57.4)\n","Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.0)\n","  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph==0.2.22)\n","  Downloading langgraph_checkpoint-1.0.12-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.18.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (24.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (4.12.2)\n","Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph==0.2.22) (1.1.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (3.10.12)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.3.0) (2024.12.14)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (3.1.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.2.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (3.0.0)\n","Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_checkpoint-1.0.12-py3-none-any.whl (17 kB)\n","Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenacity, tiktoken, langsmith, langgraph-checkpoint, langchain-openai, langgraph, langchain\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.2.3\n","    Uninstalling langsmith-0.2.3:\n","      Successfully uninstalled langsmith-0.2.3\n","  Attempting uninstall: langchain\n","    Found existing installation: langchain 0.3.12\n","    Uninstalling langchain-0.3.12:\n","      Successfully uninstalled langchain-0.3.12\n","Successfully installed langchain-0.3.0 langchain-openai-0.2.0 langgraph-0.2.22 langgraph-checkpoint-1.0.12 langsmith-0.1.147 tenacity-8.5.0 tiktoken-0.8.0\n"]}],"source":["!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22"]},{"cell_type":"code","source":["import operator\n","from typing import Annotated, Any, Optional\n","\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_openai import ChatOpenAI\n","from langgraph.graph import END, StateGraph\n","from pydantic import BaseModel, Field\n","\n","import os\n","from google.colab import userdata\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n","os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n","os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n","os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n","os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\"\n","\n","# ペルソナを表すデータモデル\n","class Persona(BaseModel):\n","    name: str = Field(..., description=\"ペルソナの名前\")\n","    background: str = Field(..., description=\"ペルソナの持つ背景\")\n","\n","\n","# ペルソナのリストを表すデータモデル\n","class Personas(BaseModel):\n","    personas: list[Persona] = Field(\n","        default_factory=list, description=\"ペルソナのリスト\"\n","    )\n","\n","\n","# インタビュー内容を表すデータモデル\n","class Interview(BaseModel):\n","    persona: Persona = Field(..., description=\"インタビュー対象のペルソナ\")\n","    question: str = Field(..., description=\"インタビューでの質問\")\n","    answer: str = Field(..., description=\"インタビューでの回答\")\n","\n","\n","# インタビュー結果のリストを表すデータモデル\n","class InterviewResult(BaseModel):\n","    interviews: list[Interview] = Field(\n","        default_factory=list, description=\"インタビュー結果のリスト\"\n","    )\n","\n","\n","# 要件定義生成AIエージェントのステート\n","class InterviewState(BaseModel):\n","    user_request: str = Field(..., description=\"ユーザーからのリクエスト\")\n","    personas: Annotated[list[Persona], operator.add] = Field(\n","        default_factory=list, description=\"生成されたペルソナのリスト\"\n","    )\n","    interviews: Annotated[list[Interview], operator.add] = Field(\n","        default_factory=list, description=\"実施されたインタビューのリスト\"\n","    )\n","    requirements_doc: str = Field(default=\"\", description=\"生成された要件定義\")\n","    iteration: int = Field(\n","        default=0, description=\"ペルソナ生成とインタビューの反復回数\"\n","    )\n","    # ↓ 情報の十分性を評価するクラスを省略するので、このあたりのフラグを削除します\n","    # is_information_sufficient: bool = Field(\n","    #     default=False, description=\"情報が十分かどうか\"\n","    # )\n","\n","\n","# ペルソナを生成するクラス\n","class PersonaGenerator:\n","    def __init__(self, llm: ChatOpenAI, k: int = 5):\n","        self.llm = llm.with_structured_output(Personas)\n","        self.k = k\n","\n","    def run(self, user_request: str) -> Personas:\n","        # プロンプトテンプレートを定義\n","        prompt = ChatPromptTemplate.from_messages(\n","            [\n","                (\n","                    \"system\",\n","                    \"あなたはユーザーインタビュー用の多様なペルソナを作成する専門家です。\",\n","                ),\n","                (\n","                    \"human\",\n","                    f\"以下のユーザーリクエストに関するインタビュー用に、{self.k}人の多様なペルソナを生成してください。\\n\\n\"\n","                    \"ユーザーリクエスト: {user_request}\\n\\n\"\n","                    \"各ペルソナには名前と簡単な背景を含めてください。年齢、性別、職業、技術的専門知識において多様性を確保してください。\",\n","                ),\n","            ]\n","        )\n","        # ペルソナ生成のためのチェーンを作成\n","        chain = prompt | self.llm\n","        # ペルソナを生成\n","        return chain.invoke({\"user_request\": user_request})\n","\n","\n","# インタビューを実施するクラス\n","class InterviewConductor:\n","    def __init__(self, llm: ChatOpenAI):\n","        self.llm = llm\n","\n","    def run(self, user_request: str, personas: list[Persona]) -> InterviewResult:\n","        # 質問を生成\n","        questions = self._generate_questions(\n","            user_request=user_request, personas=personas\n","        )\n","        # 回答を生成\n","        answers = self._generate_answers(personas=personas, questions=questions)\n","        # 質問と回答の組み合わせからインタビューリストを作成\n","        interviews = self._create_interviews(\n","            personas=personas, questions=questions, answers=answers\n","        )\n","        # インタビュー結果を返す\n","        return InterviewResult(interviews=interviews)\n","\n","    def _generate_questions(\n","        self, user_request: str, personas: list[Persona]\n","    ) -> list[str]:\n","        # 質問生成のためのプロンプトを定義\n","        question_prompt = ChatPromptTemplate.from_messages(\n","            [\n","                (\n","                    \"system\",\n","                    \"あなたはユーザー要件に基づいて適切な質問を生成する専門家です。\",\n","                ),\n","                (\n","                    \"human\",\n","                    \"以下のペルソナに関連するユーザーリクエストについて、1つの質問を生成してください。\\n\\n\"\n","                    \"ユーザーリクエスト: {user_request}\\n\"\n","                    \"ペルソナ: {persona_name} - {persona_background}\\n\\n\"\n","                    \"質問は具体的で、このペルソナの視点から重要な情報を引き出すように設計してください。\",\n","                ),\n","            ]\n","        )\n","        # 質問生成のためのチェーンを作成\n","        question_chain = question_prompt | self.llm | StrOutputParser()\n","\n","        # 各ペルソナに対する質問クエリを作成\n","        question_queries = [\n","            {\n","                \"user_request\": user_request,\n","                \"persona_name\": persona.name,\n","                \"persona_background\": persona.background,\n","            }\n","            for persona in personas\n","        ]\n","        # 質問をバッチ処理で生成\n","        return question_chain.batch(question_queries)\n","\n","    def _generate_answers(\n","        self, personas: list[Persona], questions: list[str]\n","    ) -> list[str]:\n","        # 回答生成のためのプロンプトを定義\n","        answer_prompt = ChatPromptTemplate.from_messages(\n","            [\n","                (\n","                    \"system\",\n","                    \"あなたは以下のペルソナとして回答しています: {persona_name} - {persona_background}\",\n","                ),\n","                (\"human\", \"質問: {question}\"),\n","            ]\n","        )\n","        # 回答生成のためのチェーンを作成\n","        answer_chain = answer_prompt | self.llm | StrOutputParser()\n","\n","        # 各ペルソナに対する回答クエリを作成\n","        answer_queries = [\n","            {\n","                \"persona_name\": persona.name,\n","                \"persona_background\": persona.background,\n","                \"question\": question,\n","            }\n","            for persona, question in zip(personas, questions)\n","        ]\n","        # 回答をバッチ処理で生成\n","        return answer_chain.batch(answer_queries)\n","\n","    def _create_interviews(\n","        self, personas: list[Persona], questions: list[str], answers: list[str]\n","    ) -> list[Interview]:\n","        # ペルソナ毎に質問と回答の組み合わせからインタビューオブジェクトを作成\n","        return [\n","            Interview(persona=persona, question=question, answer=answer)\n","            for persona, question, answer in zip(personas, questions, answers)\n","        ]\n","\n","\n","# （情報の十分性を評価するクラスは削除）\n","\n","# 要件定義書を生成するクラス\n","class RequirementsDocumentGenerator:\n","    def __init__(self, llm: ChatOpenAI):\n","        self.llm = llm\n","\n","    def run(self, user_request: str, interviews: list[Interview]) -> str:\n","        # プロンプトを定義\n","        prompt = ChatPromptTemplate.from_messages(\n","            [\n","                (\n","                    \"system\",\n","                    \"あなたは収集した情報に基づいて要件文書を作成する専門家です。\",\n","                ),\n","                (\n","                    \"human\",\n","                    \"以下のユーザーリクエストと複数のペルソナからのインタビュー結果に基づいて、要件文書を作成してください。\\n\\n\"\n","                    \"ユーザーリクエスト: {user_request}\\n\\n\"\n","                    \"インタビュー結果:\\n{interview_results}\\n\"\n","                    \"要件文書には以下のセクションを含めてください:\\n\"\n","                    \"1. プロジェクト概要\\n\"\n","                    \"2. 主要機能\\n\"\n","                    \"3. 非機能要件\\n\"\n","                    \"4. 制約条件\\n\"\n","                    \"5. ターゲットユーザー\\n\"\n","                    \"6. 優先順位\\n\"\n","                    \"7. リスクと軽減策\\n\\n\"\n","                    \"出力は必ず日本語でお願いします。\\n\\n要件文書:\",\n","                ),\n","            ]\n","        )\n","        # 要件定義書を生成するチェーンを作成\n","        chain = prompt | self.llm | StrOutputParser()\n","        # 要件定義書を生成\n","        return chain.invoke(\n","            {\n","                \"user_request\": user_request,\n","                \"interview_results\": \"\\n\".join(\n","                    f\"ペルソナ: {i.persona.name} - {i.persona.background}\\n\"\n","                    f\"質問: {i.question}\\n回答: {i.answer}\\n\"\n","                    for i in interviews\n","                ),\n","            }\n","        )\n","\n","\n","# 要件定義書生成AIエージェントのクラス\n","class DocumentationAgent:\n","    def __init__(self, llm: ChatOpenAI, k: Optional[int] = None):\n","        # 各種ジェネレータの初期化\n","        self.persona_generator = PersonaGenerator(llm=llm, k=k)\n","        self.interview_conductor = InterviewConductor(llm=llm)\n","        # ↓ InformationEvaluator を利用しないので削除\n","        # self.information_evaluator = InformationEvaluator(llm=llm)\n","        self.requirements_generator = RequirementsDocumentGenerator(llm=llm)\n","\n","        # グラフの作成\n","        self.graph = self._create_graph()\n","\n","    def _create_graph(self) -> StateGraph:\n","        # グラフの初期化\n","        workflow = StateGraph(InterviewState)\n","\n","        # ノードの追加（必要な部分のみ）\n","        workflow.add_node(\"generate_personas\", self._generate_personas)\n","        workflow.add_node(\"conduct_interviews\", self._conduct_interviews)\n","        workflow.add_node(\"generate_requirements\", self._generate_requirements)\n","\n","        # エントリーポイントの設定\n","        workflow.set_entry_point(\"generate_personas\")\n","\n","        # ノード間のエッジの追加\n","        workflow.add_edge(\"generate_personas\", \"conduct_interviews\")\n","        # 情報評価はスキップし、直接要件定義書生成へ\n","        workflow.add_edge(\"conduct_interviews\", \"generate_requirements\")\n","\n","        # 終了処理\n","        workflow.add_edge(\"generate_requirements\", END)\n","\n","        # グラフのコンパイル\n","        return workflow.compile()\n","\n","    def _generate_personas(self, state: InterviewState) -> dict[str, Any]:\n","        # ペルソナの生成\n","        new_personas: Personas = self.persona_generator.run(state.user_request)\n","        return {\n","            \"personas\": new_personas.personas,\n","            \"iteration\": state.iteration + 1,\n","        }\n","\n","    def _conduct_interviews(self, state: InterviewState) -> dict[str, Any]:\n","        # インタビューの実施\n","        # ペルソナの最後の5人のみを対象に\n","        new_interviews: InterviewResult = self.interview_conductor.run(\n","            state.user_request, state.personas[-5:]\n","        )\n","        return {\"interviews\": new_interviews.interviews}\n","\n","    # ↓ 情報を評価する工程は削除\n","    # def _evaluate_information(self, state: InterviewState) -> dict[str, Any]:\n","    #     ...\n","\n","    def _generate_requirements(self, state: InterviewState) -> dict[str, Any]:\n","        # 要件定義書の生成\n","        requirements_doc: str = self.requirements_generator.run(\n","            state.user_request, state.interviews\n","        )\n","        return {\"requirements_doc\": requirements_doc}\n","\n","    def run(self, user_request: str) -> str:\n","        # 初期状態の設定\n","        initial_state = InterviewState(user_request=user_request)\n","        # グラフの実行\n","        final_state = self.graph.invoke(initial_state)\n","        # 最終的な要件定義書の取得\n","        return final_state[\"requirements_doc\"]\n","\n","\n","# メイン関数\n","def main():\n","    # ユーザー入力を受け取る\n","    user_request = input(\"作成したいアプリケーションについて記載してください: \")\n","    k = 3  # ペルソナの人数（必要に応じて変更可能）\n","\n","    # ChatOpenAIモデルを初期化\n","    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0)\n","\n","    # 要件定義書生成AIエージェントを初期化\n","    agent = DocumentationAgent(llm=llm, k=k)\n","\n","    # エージェントを実行して最終的な出力を取得\n","    final_output = agent.run(user_request=user_request)\n","\n","    # 最終的な出力を表示\n","    print(final_output)\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X2CUZz5uz6-d","executionInfo":{"status":"ok","timestamp":1735088870662,"user_tz":-540,"elapsed":67441,"user":{"displayName":"Shohei O","userId":"12040440607234237913"}},"outputId":"885a6569-a48b-4678-8aa8-f5060383ca79"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["作成したいアプリケーションについて記載してください: プロジェクトの要件定義書生成AIエージェント\n","# 要件定義書\n","\n","## 1. プロジェクト概要\n","本プロジェクトは、ITプロジェクトマネージャーやUXデザイナー、フリーランスのソフトウェアエンジニアなど、さまざまなユーザーが効率的に要件定義書を生成できるAIエージェントの開発を目的としています。ユーザーのニーズに応じたカスタマイズ可能なテンプレートや過去のプロジェクトデータの活用、チームメンバーとのコラボレーション機能を提供し、要件定義書作成のプロセスを簡素化します。\n","\n","## 2. 主要機能\n","1. **テンプレートの提供**: 業界やプロジェクトの種類に応じたカスタマイズ可能なテンプレートを提供。\n","2. **過去のプロジェクトデータの活用**: 過去のプロジェクトからのデータを分析し、類似プロジェクトに対して適切な要件を提案。\n","3. **チームメンバーとのコラボレーション機能**: リアルタイムでの共同編集やコメント機能、役割に応じたアクセス権限の設定。\n","4. **自動化されたフィードバック機能**: 要件定義書の内容に対して自動的にフィードバックを提供し、抜けや矛盾を指摘。\n","5. **インテグレーション機能**: プロジェクト管理ツールやコミュニケーションツールとの連携。\n","\n","## 3. 非機能要件\n","1. **使いやすさ（Usability）**: インターフェースは直感的で、ユーザーが迷わずに操作できること。\n","2. **アクセシビリティ**: 視覚や聴覚に障害のある方への配慮を含むアクセシビリティ基準の遵守。\n","3. **一貫性**: デザインの一貫性を保ち、ユーザーが安心して利用できるようにする。\n","4. **パフォーマンスと応答性**: システムのパフォーマンスや応答速度を最適化し、快適な利用を実現。\n","\n","## 4. 制約条件\n","- プロジェクトの予算は限られており、コスト管理が重要。\n","- スケジュールは厳守する必要があり、各フェーズのタイムラインを明確に設定すること。\n","- セキュリティ面での配慮が必要であり、ユーザーのデータを適切に保護すること。\n","\n","## 5. ターゲットユーザー\n","- ITプロジェクトマネージャー（例: 佐藤健一）\n","- UXデザイナー（例: 山田美咲）\n","- フリーランスのソフトウェアエンジニア（例: アリ・アリフ）\n","\n","## 6. 優先順位\n","1. テンプレートの提供\n","2. チームメンバーとのコラボレーション機能\n","3. 過去のプロジェクトデータの活用\n","4. 自動化されたフィードバック機能\n","5. インテグレーション機能\n","\n","## 7. リスクと軽減策\n","- **リスク**: ユーザーが求める機能が実装されない可能性。\n","  - **軽減策**: ユーザーインタビューを通じてニーズを明確にし、開発プロセスに反映させる。\n","  \n","- **リスク**: プロジェクトのスケジュール遅延。\n","  - **軽減策**: 各フェーズの進捗を定期的に確認し、必要に応じてリソースを再配分する。\n","\n","- **リスク**: セキュリティの脆弱性。\n","  - **軽減策**: セキュリティ専門家によるレビューを実施し、適切な対策を講じる。\n","\n","以上が要件定義書の内容です。この文書を基に、プロジェクトの進行を円滑に進めていくことを目指します。\n"]}]}]}