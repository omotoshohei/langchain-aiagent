{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22 httpx==0.27.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0qYIfSkXLuC",
        "outputId": "d241e83d-32ad-430b-c6f1-f4fe1b5e3621"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.0\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-openai==0.2.0\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langgraph==0.2.22\n",
            "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting httpx==0.27.2\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (6.0.2)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain==0.3.0)\n",
            "  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (3.11.15)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Downloading langchain_core-0.3.60-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain==0.3.0)\n",
            "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1 (from langchain==0.3.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai==0.2.0)\n",
            "  Downloading openai-1.79.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.0)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph==0.2.22)\n",
            "  Downloading langgraph_checkpoint-1.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.27.2) (1.3.1)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx==0.27.2) (0.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.20.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (4.13.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph==0.2.22) (1.1.0)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0)\n",
            "  Downloading orjson-3.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0)\n",
            "  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (2.4.0)\n",
            "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain==0.3.0)\n",
            "  Downloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.60-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Downloading langgraph_checkpoint-1.0.12-py3-none-any.whl (17 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.79.0-py3-none-any.whl (683 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m683.3/683.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.2/352.2 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.18-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: tenacity, packaging, orjson, numpy, jsonpointer, jiter, greenlet, tiktoken, SQLAlchemy, requests-toolbelt, jsonpatch, httpx, openai, langsmith, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.1.2\n",
            "    Uninstalling tenacity-9.1.2:\n",
            "      Successfully uninstalled tenacity-9.1.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "google-genai 1.15.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SQLAlchemy-2.0.41 greenlet-3.2.2 httpx-0.27.2 jiter-0.10.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-core-0.3.60 langchain-openai-0.2.0 langchain-text-splitters-0.3.8 langgraph-0.2.22 langgraph-checkpoint-1.0.12 langsmith-0.1.147 numpy-1.26.4 openai-1.79.0 orjson-3.10.18 packaging-24.2 requests-toolbelt-1.0.0 tenacity-8.5.0 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 日本語"
      ],
      "metadata": {
        "id": "BM6FBjY8gxpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Any, Optional\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import END, StateGraph\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# 環境変数設定（Colabでの実行を想定したサンプル）\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ],
      "metadata": {
        "id": "Mn2CLqXKzQ24"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Any, Optional\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import END, StateGraph\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# 環境変数設定（Colabでの実行を想定したサンプル）\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 1. データモデル\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "# ペルソナを表すデータモデル\n",
        "class Persona(BaseModel):\n",
        "    name: str = Field(..., description=\"ペルソナの名前\")\n",
        "    background: str = Field(..., description=\"ペルソナの持つ背景\")\n",
        "    # 追加例: 検索意図や知識レベル、利用デバイス等\n",
        "    knowledge_level: Optional[str] = Field(None, description=\"トピックに対する知識レベル\")\n",
        "    search_motivation: Optional[str] = Field(None, description=\"検索の主目的・動機\")\n",
        "\n",
        "# ペルソナのリストを表すデータモデル\n",
        "class Personas(BaseModel):\n",
        "    personas: list[Persona] = Field(\n",
        "        default_factory=list, description=\"ペルソナのリスト\"\n",
        "    )\n",
        "\n",
        "# インタビュー内容を表すデータモデル（1つの質問→回答ペア）\n",
        "class Interview(BaseModel):\n",
        "    persona: Persona = Field(..., description=\"インタビュー対象のペルソナ\")\n",
        "    question: str = Field(..., description=\"インタビューでの質問\")\n",
        "    answer: str = Field(..., description=\"インタビューでの回答\")\n",
        "\n",
        "# インタビュー結果のリスト\n",
        "class InterviewResult(BaseModel):\n",
        "    interviews: list[Interview] = Field(\n",
        "        default_factory=list, description=\"インタビュー結果のリスト\"\n",
        "    )\n",
        "\n",
        "# SEO用の情報をまとめるデータモデル例\n",
        "class SEOData(BaseModel):\n",
        "    main_keywords: list[str] = Field(default_factory=list)\n",
        "    sub_keywords: list[str] = Field(default_factory=list)\n",
        "    search_intent_analysis: str = Field(\"\", description=\"検索意図のまとめや考察など\")\n",
        "\n",
        "# エージェントのステート\n",
        "class InterviewState(BaseModel):\n",
        "    user_request: str = Field(..., description=\"ユーザーからのリクエスト\")\n",
        "    personas: Annotated[list[Persona], operator.add] = Field(\n",
        "        default_factory=list, description=\"生成されたペルソナのリスト\"\n",
        "    )\n",
        "    interviews: Annotated[list[Interview], operator.add] = Field(\n",
        "        default_factory=list, description=\"実施されたインタビューのリスト\"\n",
        "    )\n",
        "    # 要約後のインタビューを保持するフィールド\n",
        "    summarized_interviews: Annotated[list[Interview], operator.add] = Field(\n",
        "        default_factory=list, description=\"重複を排除・要約したインタビュー内容\"\n",
        "    )\n",
        "    seo_data: Optional[SEOData] = Field(\n",
        "        default=None, description=\"自動生成されたSEO関連情報\"\n",
        "    )\n",
        "    requirements_doc: str = Field(default=\"\", description=\"生成された要件定義(記事作成指示書)\")\n",
        "    iteration: int = Field(\n",
        "        default=0, description=\"ペルソナ生成とインタビューの反復回数\"\n",
        "    )\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 2. 各ステップのクラス\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "# (A) ペルソナ生成クラス\n",
        "class PersonaGenerator:\n",
        "    def __init__(self, llm: ChatOpenAI, k: int = 5):\n",
        "        self.llm = llm.with_structured_output(Personas)\n",
        "        self.k = k\n",
        "\n",
        "    def run(self, user_request: str) -> Personas:\n",
        "        # プロンプトテンプレートを定義（検索意図や知識レベル等も含める）\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"あなたはブログ記事のターゲットユーザーのペルソナを作成する専門家です。\"\n",
        "                    \"複数の属性（検索意図、知識レベル、利用デバイスなど）も考慮してください。\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    f\"以下のブログ記事のトピックに関するインタビュー用に、{self.k}人の多様なペルソナを生成してください。\\n\\n\"\n",
        "                    \"トピック: {user_request}\\n\\n\"\n",
        "                    \"各読者ペルソナには以下を含めてください:\\n\"\n",
        "                    \"- 名前\\n\"\n",
        "                    \"- 簡単な背景（年齢、性別、職業など）\\n\"\n",
        "                    \"- トピックに対する知識レベル\\n\"\n",
        "                    \"- 検索の主目的や動機\\n\"\n",
        "                    \"年齢・職業・検索意図・知識レベルのバリエーションを確保してください。\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        chain = prompt | self.llm\n",
        "        return chain.invoke({\"user_request\": user_request})\n",
        "\n",
        "\n",
        "# (B) インタビュー実施クラス（複数質問対応）\n",
        "class InterviewConductor:\n",
        "    def __init__(self, llm: ChatOpenAI, n_questions: int = 3):\n",
        "        \"\"\"\n",
        "        :param n_questions: 各ペルソナに対して生成する質問数\n",
        "        \"\"\"\n",
        "        self.llm = llm\n",
        "        self.n_questions = n_questions\n",
        "\n",
        "    def run(self, user_request: str, personas: list[Persona]) -> InterviewResult:\n",
        "        interviews = []\n",
        "        for persona in personas:\n",
        "            # ペルソナごとに複数の質問を作成\n",
        "            questions = self._generate_questions(user_request, persona, self.n_questions)\n",
        "            # それぞれに回答を取得\n",
        "            answers = self._generate_answers(persona, questions)\n",
        "            # Interview のリストを構築して結合\n",
        "            for q, a in zip(questions, answers):\n",
        "                interviews.append(\n",
        "                    Interview(persona=persona, question=q, answer=a)\n",
        "                )\n",
        "        return InterviewResult(interviews=interviews)\n",
        "\n",
        "    def _generate_questions(self, user_request: str, persona: Persona, n: int) -> list[str]:\n",
        "        \"\"\"\n",
        "        1回の呼び出しでn個の質問をまとめて生成する実装例。\n",
        "        \"\"\"\n",
        "        question_prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"あなたは優秀なインタビュアーです。ペルソナが抱える悩みや課題を深堀りする質問を作成します。\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    \"以下の読者ペルソナが、ブログ記事トピック({user_request})に関して抱える悩みや課題を引き出す、\"\n",
        "                    f\"オープンな質問を{n}個作成してください。\\n\\n\"\n",
        "                    \"読者ペルソナ:\\n\"\n",
        "                    \"名前: {persona_name}\\n\"\n",
        "                    \"背景: {persona_background}\\n\"\n",
        "                    \"知識レベル: {knowledge_level}\\n\"\n",
        "                    \"検索の主目的: {search_motivation}\\n\"\n",
        "                    \"それぞれシンプルかつ深堀りできる内容にしてください。\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        question_chain = question_prompt | self.llm | StrOutputParser()\n",
        "        questions_text = question_chain.invoke(\n",
        "            {\n",
        "                \"user_request\": user_request,\n",
        "                \"persona_name\": persona.name,\n",
        "                \"persona_background\": persona.background,\n",
        "                \"knowledge_level\": persona.knowledge_level or \"不明\",\n",
        "                \"search_motivation\": persona.search_motivation or \"不明\",\n",
        "            }\n",
        "        )\n",
        "        # 箇条書き出力を分割（例: 「1. ～\\n2. ～」のようなフォーマットを想定）\n",
        "        lines = questions_text.split(\"\\n\")\n",
        "        filtered = [x.strip(\"0123456789. \") for x in lines if x.strip()]\n",
        "        return filtered\n",
        "\n",
        "    def _generate_answers(self, persona: Persona, questions: list[str]) -> list[str]:\n",
        "        answers = []\n",
        "        for q in questions:\n",
        "            answer_prompt = ChatPromptTemplate.from_messages(\n",
        "                [\n",
        "                    (\n",
        "                        \"system\",\n",
        "                        \"あなたは以下の読者ペルソナになりきっています。\"\n",
        "                        \"インタビュアーの質問に対して、具体的な悩みや課題、期待する解決策をできるだけ詳細に教えてください。\"\n",
        "                    ),\n",
        "                    (\n",
        "                        \"human\",\n",
        "                        \"ペルソナ:\\n\"\n",
        "                        \"名前: {persona_name}\\n\"\n",
        "                        \"背景: {persona_background}\\n\"\n",
        "                        \"知識レベル: {knowledge_level}\\n\"\n",
        "                        \"検索の主目的: {search_motivation}\\n\"\n",
        "                        \"質問: {question}\"\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            answer_chain = answer_prompt | self.llm | StrOutputParser()\n",
        "            ans = answer_chain.invoke(\n",
        "                {\n",
        "                    \"persona_name\": persona.name,\n",
        "                    \"persona_background\": persona.background,\n",
        "                    \"knowledge_level\": persona.knowledge_level or \"不明\",\n",
        "                    \"search_motivation\": persona.search_motivation or \"不明\",\n",
        "                    \"question\": q,\n",
        "                }\n",
        "            )\n",
        "            answers.append(ans)\n",
        "        return answers\n",
        "\n",
        "\n",
        "# (C) 回答サマリ/重複排除ステップ\n",
        "class InterviewSummarizer:\n",
        "    def __init__(self, llm: ChatOpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def run(self, interviews: list[Interview]) -> list[Interview]:\n",
        "        \"\"\"\n",
        "        簡易的に、同一ペルソナ内で重複や類似点が多い回答を要約する例。\n",
        "        \"\"\"\n",
        "        persona_buckets = {}\n",
        "        for iv in interviews:\n",
        "            key = iv.persona.name\n",
        "            if key not in persona_buckets:\n",
        "                persona_buckets[key] = []\n",
        "            persona_buckets[key].append(iv)\n",
        "\n",
        "        summarized_interviews = []\n",
        "\n",
        "        for persona_name, iv_list in persona_buckets.items():\n",
        "            # まとめて要約プロンプトを呼ぶ\n",
        "            combined_text = \"\"\n",
        "            for iv in iv_list:\n",
        "                combined_text += f\"- 質問: {iv.question}\\n  回答: {iv.answer}\\n\"\n",
        "\n",
        "            summary_prompt = ChatPromptTemplate.from_messages(\n",
        "                [\n",
        "                    (\n",
        "                        \"system\",\n",
        "                        \"あなたはインタビュー回答の要約をする専門家です。重複表現や同じ趣旨の回答をまとめ、より分かりやすく整理してください。\"\n",
        "                    ),\n",
        "                    (\n",
        "                        \"human\",\n",
        "                        \"以下は同一ペルソナから得られた複数の質問・回答です。内容が重複する場合はまとめて要約してください。\\n\\n\"\n",
        "                        \"{combined_text}\\n\\n\"\n",
        "                        \"要約・再編後のフォーマット:\\n\"\n",
        "                        \"1) 質問\\n   回答\\n\"\n",
        "                        \"2) 質問\\n   回答\\n\"\n",
        "                        \"…\"\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            summary_chain = summary_prompt | self.llm | StrOutputParser()\n",
        "            summary_text = summary_chain.invoke({\"combined_text\": combined_text})\n",
        "\n",
        "            lines = summary_text.split(\"\\n\")\n",
        "            current_q = None\n",
        "            current_a = None\n",
        "\n",
        "            def save_qa_if_valid():\n",
        "                if current_q and current_a:\n",
        "                    summarized_interviews.append(\n",
        "                        Interview(\n",
        "                            persona=iv_list[0].persona,  # 同一ペルソナのため\n",
        "                            question=current_q,\n",
        "                            answer=current_a\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            for line in lines:\n",
        "                line_stripped = line.strip()\n",
        "                if line_stripped.startswith(\"質問\"):\n",
        "                    save_qa_if_valid()\n",
        "                    current_q = line_stripped.replace(\"質問\", \"\").strip(\":： \")\n",
        "                    current_a = None\n",
        "                elif line_stripped.startswith(\"回答\"):\n",
        "                    current_a = line_stripped.replace(\"回答\", \"\").strip(\":： \")\n",
        "                else:\n",
        "                    if current_a is None and current_q is not None:\n",
        "                        current_q += \" \" + line_stripped\n",
        "                    elif current_a is not None:\n",
        "                        current_a += \" \" + line_stripped\n",
        "\n",
        "            # 最後に残ったQAを登録\n",
        "            save_qa_if_valid()\n",
        "\n",
        "        return summarized_interviews\n",
        "\n",
        "\n",
        "# (D) SEO情報生成ステップ\n",
        "class SEODataGenerator:\n",
        "    def __init__(self, llm: ChatOpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def run(self, user_request: str) -> SEOData:\n",
        "        seo_prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"あなたはSEOの専門家です。ユーザーが検索エンジンで入力するキーワードを分析し、主要キーワードと関連キーワードを提案してください。\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    \"以下のブログ記事のトピックに関して、想定される主キーワードとサブキーワードを挙げ、それぞれの検索意図も簡潔に整理してください。\\n\\n\"\n",
        "                    \"トピック: {user_request}\\n\\n\"\n",
        "                    \"フォーマット例:\\n\"\n",
        "                    \"メインキーワード:\\n- ...\\n\\n\"\n",
        "                    \"サブキーワード:\\n- ...\\n\\n\"\n",
        "                    \"検索意図:\\n...\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        chain = seo_prompt | self.llm | StrOutputParser()\n",
        "        seo_text = chain.invoke({\"user_request\": user_request})\n",
        "\n",
        "        lines = seo_text.split(\"\\n\")\n",
        "        main_keywords = []\n",
        "        sub_keywords = []\n",
        "        search_intent_analysis = []\n",
        "\n",
        "        bucket = None\n",
        "        for line in lines:\n",
        "            line_strip = line.strip()\n",
        "            if \"メインキーワード\" in line_strip:\n",
        "                bucket = \"main\"\n",
        "                continue\n",
        "            if \"サブキーワード\" in line_strip:\n",
        "                bucket = \"sub\"\n",
        "                continue\n",
        "            if \"検索意図\" in line_strip:\n",
        "                bucket = \"intent\"\n",
        "                continue\n",
        "\n",
        "            if bucket == \"main\" and line_strip.startswith(\"-\"):\n",
        "                main_keywords.append(line_strip.strip(\"- \").strip())\n",
        "            elif bucket == \"sub\" and line_strip.startswith(\"-\"):\n",
        "                sub_keywords.append(line_strip.strip(\"- \").strip())\n",
        "            elif bucket == \"intent\":\n",
        "                search_intent_analysis.append(line_strip)\n",
        "\n",
        "        return SEOData(\n",
        "            main_keywords=main_keywords,\n",
        "            sub_keywords=sub_keywords,\n",
        "            search_intent_analysis=\"\\n\".join(search_intent_analysis),\n",
        "        )\n",
        "\n",
        "\n",
        "# (E) 自己評価ステップ【削除】\n",
        "\n",
        "\n",
        "# (F) 記事作成の指示書生成クラス\n",
        "class RequirementsDocumentGenerator:\n",
        "    def __init__(self, llm: ChatOpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        user_request: str,\n",
        "        interviews: list[Interview],\n",
        "        seo_data: SEOData\n",
        "    ) -> str:\n",
        "        # インタビュー結果をテキスト形式にまとめる\n",
        "        interview_results_text = \"\\n\".join(\n",
        "            f\"ペルソナ: {i.persona.name} - {i.persona.background}\\n\"\n",
        "            f\"質問: {i.question}\\n回答: {i.answer}\\n\"\n",
        "            for i in interviews\n",
        "        )\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"あなたは収集した情報に基づいてブログ記事作成の指示書を作成する専門家です。\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    \"以下のブログ記事のトピックと複数の読者ペルソナからのインタビュー結果、さらにSEO情報に基づいて、\"\n",
        "                    \"網羅的な記事作成の指示書を作成してください。\\n\\n\"\n",
        "                    \"トピック: {user_request}\\n\\n\"\n",
        "                    \"インタビュー結果:\\n{interview_results}\\n\"\n",
        "                    \"SEO情報:\\n\"\n",
        "                    \"メインキーワード: {main_kw}\\n\"\n",
        "                    \"サブキーワード: {sub_kw}\\n\"\n",
        "                    \"検索意図分析: {intent_analysis}\\n\\n\"\n",
        "                    \"記事作成の指示書には以下のセクションを含めてください:\\n\"\n",
        "                    \"1. 記事の目的\\n\"\n",
        "                    \"2. ターゲット読者\\n\"\n",
        "                    \"3. 読者の悩み\\n\"\n",
        "                    \"4. SEOのターゲットキーワードとトピック\\n\"\n",
        "                    \"5. 記事の構成案(見出し案含む)\\n\"\n",
        "                    \"6. 注意事項\\n\\n\"\n",
        "                    \"出力は日本語でお願いします。\\n\\n\"\n",
        "                    \"記事作成の指示書:\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        chain = prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        final_text = chain.invoke(\n",
        "            {\n",
        "                \"user_request\": user_request,\n",
        "                \"interview_results\": interview_results_text,\n",
        "                \"main_kw\": \", \".join(seo_data.main_keywords),\n",
        "                \"sub_kw\": \", \".join(seo_data.sub_keywords),\n",
        "                \"intent_analysis\": seo_data.search_intent_analysis,\n",
        "            }\n",
        "        )\n",
        "        return final_text\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 3. エージェント実行クラス (StateGraph)\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "class DocumentationAgent:\n",
        "    def __init__(self, llm: ChatOpenAI, k: Optional[int] = None):\n",
        "        # 各ステップのインスタンス化\n",
        "        self.persona_generator = PersonaGenerator(llm=llm, k=k or 3)\n",
        "        self.interview_conductor = InterviewConductor(llm=llm, n_questions=3)\n",
        "        self.interview_summarizer = InterviewSummarizer(llm=llm)\n",
        "        self.seo_data_generator = SEODataGenerator(llm=llm)\n",
        "        self.requirements_generator = RequirementsDocumentGenerator(llm=llm)\n",
        "\n",
        "        self.graph = self._create_graph()\n",
        "\n",
        "    def _create_graph(self) -> StateGraph:\n",
        "        workflow = StateGraph(InterviewState)\n",
        "\n",
        "        # ノードの追加\n",
        "        workflow.add_node(\"generate_personas\", self._generate_personas)\n",
        "        workflow.add_node(\"conduct_interviews\", self._conduct_interviews)\n",
        "        workflow.add_node(\"summarize_answers\", self._summarize_answers)\n",
        "        workflow.add_node(\"generate_seo_data\", self._generate_seo_data)\n",
        "        workflow.add_node(\"generate_requirements\", self._generate_requirements)\n",
        "\n",
        "        # エントリーポイント\n",
        "        workflow.set_entry_point(\"generate_personas\")\n",
        "\n",
        "        # 遷移設定\n",
        "        workflow.add_edge(\"generate_personas\", \"conduct_interviews\")\n",
        "        workflow.add_edge(\"conduct_interviews\", \"summarize_answers\")\n",
        "        workflow.add_edge(\"summarize_answers\", \"generate_seo_data\")\n",
        "        # 自己評価ステップを削除したので直接最終ステップへ\n",
        "        workflow.add_edge(\"generate_seo_data\", \"generate_requirements\")\n",
        "\n",
        "        # 最終ノード\n",
        "        workflow.add_edge(\"generate_requirements\", END)\n",
        "\n",
        "        return workflow.compile()\n",
        "\n",
        "    def _generate_personas(self, state: InterviewState) -> dict[str, Any]:\n",
        "        new_personas: Personas = self.persona_generator.run(state.user_request)\n",
        "        return {\n",
        "            \"personas\": new_personas.personas,\n",
        "            \"iteration\": state.iteration + 1,\n",
        "        }\n",
        "\n",
        "    def _conduct_interviews(self, state: InterviewState) -> dict[str, Any]:\n",
        "        new_personas = state.personas[-5:]  # 多い場合は最後の5人のみ\n",
        "        new_interviews = self.interview_conductor.run(state.user_request, new_personas)\n",
        "        return {\"interviews\": new_interviews.interviews}\n",
        "\n",
        "    def _summarize_answers(self, state: InterviewState) -> dict[str, Any]:\n",
        "        summarized = self.interview_summarizer.run(state.interviews)\n",
        "        return {\"summarized_interviews\": summarized}\n",
        "\n",
        "    def _generate_seo_data(self, state: InterviewState) -> dict[str, Any]:\n",
        "        seo_data = self.seo_data_generator.run(state.user_request)\n",
        "        return {\"seo_data\": seo_data}\n",
        "\n",
        "    def _generate_requirements(self, state: InterviewState) -> dict[str, Any]:\n",
        "        final_doc = self.requirements_generator.run(\n",
        "            user_request=state.user_request,\n",
        "            interviews=state.summarized_interviews,  # 要約後のインタビューを使用\n",
        "            seo_data=state.seo_data\n",
        "        )\n",
        "        return {\"requirements_doc\": final_doc}\n",
        "\n",
        "    def run(self, user_request: str) -> str:\n",
        "        initial_state = InterviewState(user_request=user_request)\n",
        "        final_state = self.graph.invoke(initial_state)\n",
        "        return final_state[\"requirements_doc\"]\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 4. メイン実行部\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    user_request = input(\"ブログ記事のトピックを記載してください: \")\n",
        "    k = 3  # ペルソナの人数\n",
        "\n",
        "    llm = ChatOpenAI(model_name=\"gpt-4.1-mini-2025-04-14\", temperature=0.3)\n",
        "    # llm = ChatOpenAI(model_name=\"gpt-4.1-2025-04-14\", temperature=0.3)\n",
        "\n",
        "\n",
        "    agent = DocumentationAgent(llm=llm, k=k)\n",
        "    final_output = agent.run(user_request=user_request)\n",
        "\n",
        "    print(\"\\n===== 最終的な記事作成指示書 =====\")\n",
        "    print(final_output)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vfkb9gGzY6X",
        "outputId": "1482a00f-7f64-4515-fdd5-f57d1a351431"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ブログ記事のトピックを記載してください: ディスプレイ広告\n",
            "\n",
            "===== 最終的な記事作成指示書 =====\n",
            "# 記事作成の指示書\n",
            "\n",
            "## 1. 記事の目的\n",
            "この記事の目的は、ディスプレイ広告に関する包括的な情報を提供し、読者がこの広告手法を理解し、実際に運用するための知識を得ることです。特に、ディスプレイ広告の効果、種類、作成方法、費用、ターゲティング、成功事例、リスティング広告との違いについて詳しく解説します。\n",
            "\n",
            "## 2. ターゲット読者\n",
            "- **マーケティング担当者**: 広告戦略を考える際にディスプレイ広告を検討している。\n",
            "- **中小企業の経営者**: 限られた予算で効果的な広告手法を模索している。\n",
            "- **広告代理店のスタッフ**: クライアントに対してディスプレイ広告の提案を行う必要がある。\n",
            "- **広告運用初心者**: ディスプレイ広告の基礎を学びたいと考えている。\n",
            "\n",
            "## 3. 読者の悩み\n",
            "- ディスプレイ広告の基本的な理解が不足している。\n",
            "- 効果的な広告戦略を構築するための具体的なデータや事例が欲しい。\n",
            "- 実際にディスプレイ広告を作成する方法や費用についての情報が不足している。\n",
            "- ターゲティングの方法や成功事例を知りたい。\n",
            "- ディスプレイ広告とリスティング広告の違いを理解し、適切な広告手法を選びたい。\n",
            "\n",
            "## 4. SEOのターゲットキーワードとトピック\n",
            "- **メインキーワード**: ディスプレイ広告\n",
            "- **サブキーワード**: \n",
            "  - ディスプレイ広告とは\n",
            "  - ディスプレイ広告の効果\n",
            "  - ディスプレイ広告の種類\n",
            "  - ディスプレイ広告の作成方法\n",
            "  - ディスプレイ広告の費用\n",
            "  - ディスプレイ広告のターゲティング\n",
            "  - ディスプレイ広告の成功事例\n",
            "  - ディスプレイ広告とリスティング広告の違い\n",
            "\n",
            "## 5. 記事の構成案(見出し案含む)\n",
            "### はじめに\n",
            "- ディスプレイ広告の重要性と目的\n",
            "\n",
            "### 1. ディスプレイ広告とは\n",
            "- 定義と基本的な仕組み\n",
            "\n",
            "### 2. ディスプレイ広告の効果\n",
            "- どのように効果を測定するか\n",
            "- 具体的な効果のデータ\n",
            "\n",
            "### 3. ディスプレイ広告の種類\n",
            "- バナー広告\n",
            "- 動画広告\n",
            "- リッチメディア広告\n",
            "- ネイティブ広告\n",
            "\n",
            "### 4. ディスプレイ広告の作成方法\n",
            "- デザインのポイント\n",
            "- コピーライティングの重要性\n",
            "- 配信プラットフォームの選定\n",
            "\n",
            "### 5. ディスプレイ広告の費用\n",
            "- 予算の考え方\n",
            "- CPC、CPM、CPAの違い\n",
            "\n",
            "### 6. ディスプレイ広告のターゲティング\n",
            "- ターゲティングの手法\n",
            "- リマーケティングの活用\n",
            "\n",
            "### 7. ディスプレイ広告の成功事例\n",
            "- 具体的な企業の成功事例\n",
            "- 成功の要因分析\n",
            "\n",
            "### 8. ディスプレイ広告とリスティング広告の違い\n",
            "- 各広告手法の特徴と使い分け\n",
            "\n",
            "### おわりに\n",
            "- ディスプレイ広告を活用するためのまとめと今後の展望\n",
            "\n",
            "## 6. 注意事項\n",
            "- 読者にとって有益な情報を提供することを最優先にし、専門用語は必要に応じて解説を加える。\n",
            "- SEO対策として、キーワードを自然に散りばめることを心がける。\n",
            "- 具体的なデータや事例を引用する際は、信頼性のある情報源を使用すること。\n",
            "- 読者の悩みを解決するための実践的なアドバイスを盛り込むことを忘れない。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 英語"
      ],
      "metadata": {
        "id": "fg81NnxXg1E8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Any, Optional\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import END, StateGraph\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Setting environment variables (example for Colab execution)\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 1. Data Models\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "class Persona(BaseModel):\n",
        "    \"\"\"Represents a persona for the blog's target audience.\"\"\"\n",
        "    name: str = Field(..., description=\"Persona's name\")\n",
        "    background: str = Field(..., description=\"Background of this persona\")\n",
        "    knowledge_level: Optional[str] = Field(None, description=\"Knowledge level about the topic\")\n",
        "    search_motivation: Optional[str] = Field(None, description=\"Main motivation or reason for searching\")\n",
        "\n",
        "\n",
        "class Personas(BaseModel):\n",
        "    \"\"\"Holds a list of Persona objects.\"\"\"\n",
        "    personas: list[Persona] = Field(default_factory=list, description=\"List of personas\")\n",
        "\n",
        "\n",
        "class Interview(BaseModel):\n",
        "    \"\"\"Represents a single interview Q&A with a persona.\"\"\"\n",
        "    persona: Persona = Field(..., description=\"The persona being interviewed\")\n",
        "    question: str = Field(..., description=\"The interview question asked\")\n",
        "    answer: str = Field(..., description=\"The persona's answer to the interview question\")\n",
        "\n",
        "\n",
        "class InterviewResult(BaseModel):\n",
        "    \"\"\"Represents the results from multiple interview Q&As.\"\"\"\n",
        "    interviews: list[Interview] = Field(default_factory=list, description=\"List of interview Q&A results\")\n",
        "\n",
        "\n",
        "class SEOData(BaseModel):\n",
        "    \"\"\"Represents SEO-related data, such as keywords and user search intent.\"\"\"\n",
        "    main_keywords: list[str] = Field(default_factory=list)\n",
        "    sub_keywords: list[str] = Field(default_factory=list)\n",
        "    search_intent_analysis: str = Field(\"\", description=\"Summary or analysis of the search intent\")\n",
        "\n",
        "\n",
        "class InterviewState(BaseModel):\n",
        "    \"\"\"\n",
        "    State object that keeps track of:\n",
        "    - The user's request (blog topic)\n",
        "    - The generated personas\n",
        "    - The interviews (Q&A pairs)\n",
        "    - Summarized interview results\n",
        "    - Generated SEO data\n",
        "    - Final requirements document for article creation\n",
        "    - Iteration count if needed\n",
        "    \"\"\"\n",
        "    user_request: str = Field(..., description=\"The request from the user (blog topic)\")\n",
        "    personas: Annotated[list[Persona], operator.add] = Field(\n",
        "        default_factory=list, description=\"List of generated personas\"\n",
        "    )\n",
        "    interviews: Annotated[list[Interview], operator.add] = Field(\n",
        "        default_factory=list, description=\"Conducted interviews\"\n",
        "    )\n",
        "    summarized_interviews: Annotated[list[Interview], operator.add] = Field(\n",
        "        default_factory=list, description=\"Interviews after deduplication/summary\"\n",
        "    )\n",
        "    seo_data: Optional[SEOData] = Field(\n",
        "        default=None, description=\"Automatically generated SEO data\"\n",
        "    )\n",
        "    requirements_doc: str = Field(default=\"\", description=\"Generated instructions for article creation\")\n",
        "    iteration: int = Field(\n",
        "        default=0, description=\"Number of iterations of persona generation and interviews\"\n",
        "    )\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 2. Classes for Each Step\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "class PersonaGenerator:\n",
        "    \"\"\"\n",
        "    Generates multiple personas for interviews.\n",
        "    \"\"\"\n",
        "    def __init__(self, llm: ChatOpenAI, k: int = 5):\n",
        "        self.llm = llm.with_structured_output(Personas)\n",
        "        self.k = k\n",
        "\n",
        "    def run(self, user_request: str) -> Personas:\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"You are an expert at creating diverse personas for a blog's target audience, \"\n",
        "                    \"including attributes like search intent and knowledge level.\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    f\"Please generate {self.k} diverse personas for interviews related to the following blog topic.\\n\\n\"\n",
        "                    \"Topic: {user_request}\\n\\n\"\n",
        "                    \"For each persona, include:\\n\"\n",
        "                    \"- Name\\n\"\n",
        "                    \"- Brief background (e.g., age, gender, occupation)\\n\"\n",
        "                    \"- Knowledge level regarding the topic\\n\"\n",
        "                    \"- Main motivation or reason for searching\\n\"\n",
        "                    \"Ensure variety in age, occupation, search intent, and knowledge level.\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        chain = prompt | self.llm\n",
        "        return chain.invoke({\"user_request\": user_request})\n",
        "\n",
        "\n",
        "class InterviewConductor:\n",
        "    \"\"\"\n",
        "    Conducts multiple interviews by generating questions and collecting answers from each persona.\n",
        "    \"\"\"\n",
        "    def __init__(self, llm: ChatOpenAI, n_questions: int = 3):\n",
        "        \"\"\"\n",
        "        :param n_questions: Number of questions to generate for each persona\n",
        "        \"\"\"\n",
        "        self.llm = llm\n",
        "        self.n_questions = n_questions\n",
        "\n",
        "    def run(self, user_request: str, personas: list[Persona]) -> InterviewResult:\n",
        "        interviews = []\n",
        "        for persona in personas:\n",
        "            # Generate multiple questions per persona\n",
        "            questions = self._generate_questions(user_request, persona, self.n_questions)\n",
        "            # Generate answers for each question\n",
        "            answers = self._generate_answers(persona, questions)\n",
        "            # Combine them into Interview objects\n",
        "            for q, a in zip(questions, answers):\n",
        "                interviews.append(\n",
        "                    Interview(persona=persona, question=q, answer=a)\n",
        "                )\n",
        "        return InterviewResult(interviews=interviews)\n",
        "\n",
        "    def _generate_questions(self, user_request: str, persona: Persona, n: int) -> list[str]:\n",
        "        \"\"\"\n",
        "        Generates n open-ended questions to draw out challenges or concerns\n",
        "        that the persona may have regarding the blog topic.\n",
        "        \"\"\"\n",
        "        question_prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"You are a skilled interviewer who creates questions to explore the persona's concerns or challenges.\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    \"Below is a persona who may have concerns or issues related to the blog topic ({user_request}).\\n\"\n",
        "                    f\"Please create {n} open-ended questions to uncover this persona's perspective.\\n\\n\"\n",
        "                    \"Persona:\\n\"\n",
        "                    \"Name: {persona_name}\\n\"\n",
        "                    \"Background: {persona_background}\\n\"\n",
        "                    \"Knowledge Level: {knowledge_level}\\n\"\n",
        "                    \"Main Motivation: {search_motivation}\\n\"\n",
        "                    \"Keep the questions simple yet probing enough to elicit detailed issues.\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        question_chain = question_prompt | self.llm | StrOutputParser()\n",
        "        questions_text = question_chain.invoke(\n",
        "            {\n",
        "                \"user_request\": user_request,\n",
        "                \"persona_name\": persona.name,\n",
        "                \"persona_background\": persona.background,\n",
        "                \"knowledge_level\": persona.knowledge_level or \"Unknown\",\n",
        "                \"search_motivation\": persona.search_motivation or \"Unknown\",\n",
        "            }\n",
        "        )\n",
        "        # Assuming bullet-point format, e.g. \"1. ...\\n2. ...\"\n",
        "        lines = questions_text.split(\"\\n\")\n",
        "        filtered = [x.strip(\"0123456789. \") for x in lines if x.strip()]\n",
        "        return filtered\n",
        "\n",
        "    def _generate_answers(self, persona: Persona, questions: list[str]) -> list[str]:\n",
        "        \"\"\"\n",
        "        Simulates persona answers to the generated questions.\n",
        "        \"\"\"\n",
        "        answers = []\n",
        "        for q in questions:\n",
        "            answer_prompt = ChatPromptTemplate.from_messages(\n",
        "                [\n",
        "                    (\n",
        "                        \"system\",\n",
        "                        \"You are now taking on the role of the following persona. \"\n",
        "                        \"Please provide detailed concerns, challenges, and any potential solutions you imagine.\"\n",
        "                    ),\n",
        "                    (\n",
        "                        \"human\",\n",
        "                        \"Persona:\\n\"\n",
        "                        \"Name: {persona_name}\\n\"\n",
        "                        \"Background: {persona_background}\\n\"\n",
        "                        \"Knowledge Level: {knowledge_level}\\n\"\n",
        "                        \"Main Motivation: {search_motivation}\\n\"\n",
        "                        \"Question: {question}\"\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            answer_chain = answer_prompt | self.llm | StrOutputParser()\n",
        "            ans = answer_chain.invoke(\n",
        "                {\n",
        "                    \"persona_name\": persona.name,\n",
        "                    \"persona_background\": persona.background,\n",
        "                    \"knowledge_level\": persona.knowledge_level or \"Unknown\",\n",
        "                    \"search_motivation\": persona.search_motivation or \"Unknown\",\n",
        "                    \"question\": q,\n",
        "                }\n",
        "            )\n",
        "            answers.append(ans)\n",
        "        return answers\n",
        "\n",
        "\n",
        "class InterviewSummarizer:\n",
        "    \"\"\"\n",
        "    Summarizes and removes redundant or overlapping answers for the same persona.\n",
        "    \"\"\"\n",
        "    def __init__(self, llm: ChatOpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def run(self, interviews: list[Interview]) -> list[Interview]:\n",
        "        \"\"\"\n",
        "        For each persona, merges similar answers and returns a summarized list of Q&A pairs.\n",
        "        \"\"\"\n",
        "        persona_buckets = {}\n",
        "        for iv in interviews:\n",
        "            key = iv.persona.name\n",
        "            if key not in persona_buckets:\n",
        "                persona_buckets[key] = []\n",
        "            persona_buckets[key].append(iv)\n",
        "\n",
        "        summarized_interviews = []\n",
        "\n",
        "        for persona_name, iv_list in persona_buckets.items():\n",
        "            combined_text = \"\"\n",
        "            for iv in iv_list:\n",
        "                combined_text += f\"- Question: {iv.question}\\n  Answer: {iv.answer}\\n\"\n",
        "\n",
        "            summary_prompt = ChatPromptTemplate.from_messages(\n",
        "                [\n",
        "                    (\n",
        "                        \"system\",\n",
        "                        \"You specialize in summarizing interview answers, merging redundant or similar points into a concise format.\"\n",
        "                    ),\n",
        "                    (\n",
        "                        \"human\",\n",
        "                        \"Below are multiple Q&A pairs from the same persona. If there's repetition, combine and summarize them.\\n\\n\"\n",
        "                        \"{combined_text}\\n\\n\"\n",
        "                        \"Use this format after summarizing:\\n\"\n",
        "                        \"1) Question\\n   Answer\\n\"\n",
        "                        \"2) Question\\n   Answer\\n\"\n",
        "                        \"...\"\n",
        "                    ),\n",
        "                ]\n",
        "            )\n",
        "            summary_chain = summary_prompt | self.llm | StrOutputParser()\n",
        "            summary_text = summary_chain.invoke({\"combined_text\": combined_text})\n",
        "\n",
        "            lines = summary_text.split(\"\\n\")\n",
        "            current_q = None\n",
        "            current_a = None\n",
        "\n",
        "            def save_qa_if_valid():\n",
        "                if current_q and current_a:\n",
        "                    summarized_interviews.append(\n",
        "                        Interview(\n",
        "                            persona=iv_list[0].persona,  # same persona\n",
        "                            question=current_q,\n",
        "                            answer=current_a\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            for line in lines:\n",
        "                line_stripped = line.strip()\n",
        "                if line_stripped.startswith(\"Question\"):\n",
        "                    # Save the previous Q&A before starting a new one\n",
        "                    save_qa_if_valid()\n",
        "                    current_q = line_stripped.replace(\"Question\", \"\").strip(\":： \")\n",
        "                    current_a = None\n",
        "                elif line_stripped.startswith(\"Answer\"):\n",
        "                    current_a = line_stripped.replace(\"Answer\", \"\").strip(\":： \")\n",
        "                else:\n",
        "                    if current_q is not None and current_a is None:\n",
        "                        current_q += \" \" + line_stripped\n",
        "                    elif current_a is not None:\n",
        "                        current_a += \" \" + line_stripped\n",
        "\n",
        "            # Save any leftover Q&A\n",
        "            save_qa_if_valid()\n",
        "\n",
        "        return summarized_interviews\n",
        "\n",
        "\n",
        "class SEODataGenerator:\n",
        "    \"\"\"\n",
        "    Generates SEO-related information such as main keywords, sub keywords, and a short analysis of user search intent.\n",
        "    \"\"\"\n",
        "    def __init__(self, llm: ChatOpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def run(self, user_request: str) -> SEOData:\n",
        "        seo_prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"You are an SEO expert. Analyze what users might search for in search engines, \"\n",
        "                    \"and propose main keywords, sub-keywords, and a brief summary of their search intentions.\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    \"For the following blog topic, list the main keywords and sub-keywords you expect users to search for, \"\n",
        "                    \"and briefly outline their search intent.\\n\\n\"\n",
        "                    \"Topic: {user_request}\\n\\n\"\n",
        "                    \"Example format:\\n\"\n",
        "                    \"Main Keywords:\\n- ...\\n\\n\"\n",
        "                    \"Sub Keywords:\\n- ...\\n\\n\"\n",
        "                    \"Search Intent:\\n...\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        chain = seo_prompt | self.llm | StrOutputParser()\n",
        "        seo_text = chain.invoke({\"user_request\": user_request})\n",
        "\n",
        "        lines = seo_text.split(\"\\n\")\n",
        "        main_keywords = []\n",
        "        sub_keywords = []\n",
        "        search_intent_analysis = []\n",
        "\n",
        "        bucket = None\n",
        "        for line in lines:\n",
        "            line_strip = line.strip()\n",
        "            if \"Main Keywords\" in line_strip:\n",
        "                bucket = \"main\"\n",
        "                continue\n",
        "            if \"Sub Keywords\" in line_strip:\n",
        "                bucket = \"sub\"\n",
        "                continue\n",
        "            if \"Search Intent\" in line_strip:\n",
        "                bucket = \"intent\"\n",
        "                continue\n",
        "\n",
        "            if bucket == \"main\" and line_strip.startswith(\"-\"):\n",
        "                main_keywords.append(line_strip.strip(\"- \").strip())\n",
        "            elif bucket == \"sub\" and line_strip.startswith(\"-\"):\n",
        "                sub_keywords.append(line_strip.strip(\"- \").strip())\n",
        "            elif bucket == \"intent\":\n",
        "                search_intent_analysis.append(line_strip)\n",
        "\n",
        "        return SEOData(\n",
        "            main_keywords=main_keywords,\n",
        "            sub_keywords=sub_keywords,\n",
        "            search_intent_analysis=\"\\n\".join(search_intent_analysis),\n",
        "        )\n",
        "\n",
        "\n",
        "class RequirementsDocumentGenerator:\n",
        "    \"\"\"\n",
        "    Generates a final requirements/instructions document for creating a blog article.\n",
        "    \"\"\"\n",
        "    def __init__(self, llm: ChatOpenAI):\n",
        "        self.llm = llm\n",
        "\n",
        "    def run(\n",
        "        self,\n",
        "        user_request: str,\n",
        "        interviews: list[Interview],\n",
        "        seo_data: SEOData\n",
        "    ) -> str:\n",
        "        # Combine interview results into text\n",
        "        interview_results_text = \"\\n\".join(\n",
        "            f\"Persona: {i.persona.name} - {i.persona.background}\\n\"\n",
        "            f\"Question: {i.question}\\nAnswer: {i.answer}\\n\"\n",
        "            for i in interviews\n",
        "        )\n",
        "\n",
        "        prompt = ChatPromptTemplate.from_messages(\n",
        "            [\n",
        "                (\n",
        "                    \"system\",\n",
        "                    \"You are an expert who creates comprehensive article instructions based on collected information.\"\n",
        "                ),\n",
        "                (\n",
        "                    \"human\",\n",
        "                    \"Using the following blog topic, multiple interview results from various personas, \"\n",
        "                    \"and the SEO information provided, please create a thorough instruction document for writing the blog article.\\n\\n\"\n",
        "                    \"Topic: {user_request}\\n\\n\"\n",
        "                    \"Interview Results:\\n{interview_results}\\n\"\n",
        "                    \"SEO Information:\\n\"\n",
        "                    \"Main Keywords: {main_kw}\\n\"\n",
        "                    \"Sub Keywords: {sub_kw}\\n\"\n",
        "                    \"Search Intent Analysis: {intent_analysis}\\n\\n\"\n",
        "                    \"Please include the following sections in the instruction document:\\n\"\n",
        "                    \"1. Purpose of the Article\\n\"\n",
        "                    \"2. Target Readers\\n\"\n",
        "                    \"3. Readers' Challenges or Pain Points\\n\"\n",
        "                    \"4. SEO Target Keywords and Topics\\n\"\n",
        "                    \"5. Proposed Article Structure (including headings)\\n\"\n",
        "                    \"6. Important Notes\\n\\n\"\n",
        "                    \"The output must be in English.\\n\\n\"\n",
        "                    \"Article Creation Instructions:\"\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "        chain = prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        final_text = chain.invoke(\n",
        "            {\n",
        "                \"user_request\": user_request,\n",
        "                \"interview_results\": interview_results_text,\n",
        "                \"main_kw\": \", \".join(seo_data.main_keywords),\n",
        "                \"sub_kw\": \", \".join(seo_data.sub_keywords),\n",
        "                \"intent_analysis\": seo_data.search_intent_analysis,\n",
        "            }\n",
        "        )\n",
        "        return final_text\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 3. The Agent Class with StateGraph\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "class DocumentationAgent:\n",
        "    \"\"\"\n",
        "    Orchestrates the entire flow:\n",
        "      1) Generate personas\n",
        "      2) Conduct interviews\n",
        "      3) Summarize answers\n",
        "      4) Generate SEO data\n",
        "      5) Produce final requirements doc\n",
        "    \"\"\"\n",
        "    def __init__(self, llm: ChatOpenAI, k: Optional[int] = None):\n",
        "        self.persona_generator = PersonaGenerator(llm=llm, k=k or 3)\n",
        "        self.interview_conductor = InterviewConductor(llm=llm, n_questions=3)\n",
        "        self.interview_summarizer = InterviewSummarizer(llm=llm)\n",
        "        self.seo_data_generator = SEODataGenerator(llm=llm)\n",
        "        self.requirements_generator = RequirementsDocumentGenerator(llm=llm)\n",
        "\n",
        "        self.graph = self._create_graph()\n",
        "\n",
        "    def _create_graph(self) -> StateGraph:\n",
        "        workflow = StateGraph(InterviewState)\n",
        "\n",
        "        # Add nodes\n",
        "        workflow.add_node(\"generate_personas\", self._generate_personas)\n",
        "        workflow.add_node(\"conduct_interviews\", self._conduct_interviews)\n",
        "        workflow.add_node(\"summarize_answers\", self._summarize_answers)\n",
        "        workflow.add_node(\"generate_seo_data\", self._generate_seo_data)\n",
        "        workflow.add_node(\"generate_requirements\", self._generate_requirements)\n",
        "\n",
        "        # Entry point\n",
        "        workflow.set_entry_point(\"generate_personas\")\n",
        "\n",
        "        # Edges\n",
        "        workflow.add_edge(\"generate_personas\", \"conduct_interviews\")\n",
        "        workflow.add_edge(\"conduct_interviews\", \"summarize_answers\")\n",
        "        workflow.add_edge(\"summarize_answers\", \"generate_seo_data\")\n",
        "        workflow.add_edge(\"generate_seo_data\", \"generate_requirements\")\n",
        "        workflow.add_edge(\"generate_requirements\", END)\n",
        "\n",
        "        return workflow.compile()\n",
        "\n",
        "    def _generate_personas(self, state: InterviewState) -> dict[str, Any]:\n",
        "        new_personas: Personas = self.persona_generator.run(state.user_request)\n",
        "        return {\n",
        "            \"personas\": new_personas.personas,\n",
        "            \"iteration\": state.iteration + 1,\n",
        "        }\n",
        "\n",
        "    def _conduct_interviews(self, state: InterviewState) -> dict[str, Any]:\n",
        "        # If there are many personas, only take the last five as an example\n",
        "        new_personas = state.personas[-5:]\n",
        "        new_interviews = self.interview_conductor.run(state.user_request, new_personas)\n",
        "        return {\"interviews\": new_interviews.interviews}\n",
        "\n",
        "    def _summarize_answers(self, state: InterviewState) -> dict[str, Any]:\n",
        "        summarized = self.interview_summarizer.run(state.interviews)\n",
        "        return {\"summarized_interviews\": summarized}\n",
        "\n",
        "    def _generate_seo_data(self, state: InterviewState) -> dict[str, Any]:\n",
        "        seo_data = self.seo_data_generator.run(state.user_request)\n",
        "        return {\"seo_data\": seo_data}\n",
        "\n",
        "    def _generate_requirements(self, state: InterviewState) -> dict[str, Any]:\n",
        "        final_doc = self.requirements_generator.run(\n",
        "            user_request=state.user_request,\n",
        "            interviews=state.summarized_interviews,\n",
        "            seo_data=state.seo_data\n",
        "        )\n",
        "        return {\"requirements_doc\": final_doc}\n",
        "\n",
        "    def run(self, user_request: str) -> str:\n",
        "        # Start with the initial state and run through the flow\n",
        "        initial_state = InterviewState(user_request=user_request)\n",
        "        final_state = self.graph.invoke(initial_state)\n",
        "        return final_state[\"requirements_doc\"]\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "# 4. Main Execution\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    user_request = input(\"Please enter your blog topic: \")\n",
        "    k = 3  # Number of personas\n",
        "\n",
        "    llm = ChatOpenAI(model_name=\"gpt-4.1-mini-2025-04-14\", temperature=0.3)\n",
        "    # llm = ChatOpenAI(model_name=\"gpt-4.1-2025-04-14\", temperature=0.3)\n",
        "\n",
        "    agent = DocumentationAgent(llm=llm, k=k)\n",
        "    final_output = agent.run(user_request=user_request)\n",
        "\n",
        "    print(\"\\n===== Final Article Creation Instructions =====\")\n",
        "    print(final_output)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiglDXIqz4DX",
        "outputId": "4d925314-50bd-49ed-9b15-335d6b96a351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter your blog topic: what is ai agent\n",
            "\n",
            "===== Final Article Creation Instructions =====\n",
            "# Article Creation Instructions: \"What is an AI Agent\"\n",
            "\n",
            "## 1. Purpose of the Article\n",
            "The purpose of this article is to provide a comprehensive overview of AI agents, including their definition, functionality, applications, and advantages over traditional software. The article aims to educate readers about the significance of AI agents in the realm of artificial intelligence and technology, while also addressing their future potential. By the end of the article, readers should have a clear understanding of what AI agents are, how they work, and their relevance in various sectors.\n",
            "\n",
            "## 2. Target Readers\n",
            "The target audience for this article includes:\n",
            "- Technology enthusiasts seeking to understand AI concepts.\n",
            "- Professionals in the tech industry looking to implement AI solutions.\n",
            "- Students and researchers studying artificial intelligence.\n",
            "- Business leaders interested in leveraging AI agents for operational efficiency.\n",
            "- General readers curious about advancements in technology.\n",
            "\n",
            "## 3. Readers' Challenges or Pain Points\n",
            "Readers may face the following challenges:\n",
            "- Lack of clear understanding of what constitutes an AI agent.\n",
            "- Difficulty distinguishing between AI agents and traditional software.\n",
            "- Uncertainty about the practical applications of AI agents in real-world scenarios.\n",
            "- Confusion regarding the technologies that enable AI agents to function.\n",
            "- Interest in the future implications and developments in AI agents but lacking accessible information.\n",
            "\n",
            "## 4. SEO Target Keywords and Topics\n",
            "### Main Keywords:\n",
            "- AI agent\n",
            "- Artificial intelligence agent\n",
            "- Intelligent agent\n",
            "\n",
            "### Sub Keywords:\n",
            "- Definition of AI agent\n",
            "- Examples of AI agents\n",
            "- How AI agents work\n",
            "- Applications of AI agents\n",
            "- Differences between AI agents and traditional software\n",
            "- Benefits of using AI agents\n",
            "- AI agent technologies\n",
            "- Future of AI agents\n",
            "\n",
            "## 5. Proposed Article Structure (including headings)\n",
            "\n",
            "### Title: What is an AI Agent? Understanding the Future of Intelligent Automation\n",
            "\n",
            "#### Introduction\n",
            "- Briefly introduce the concept of AI agents.\n",
            "- Highlight the growing importance of AI agents in technology today.\n",
            "\n",
            "#### 1. Definition of AI Agent\n",
            "- Provide a clear and concise definition of an AI agent.\n",
            "- Discuss the characteristics that define an intelligent agent.\n",
            "\n",
            "#### 2. How AI Agents Work\n",
            "- Explain the underlying technologies that power AI agents (e.g., machine learning, natural language processing).\n",
            "- Describe the processes involved in AI agent operation.\n",
            "\n",
            "#### 3. Examples of AI Agents\n",
            "- Provide real-world examples of AI agents (e.g., virtual assistants, chatbots, recommendation systems).\n",
            "- Discuss the context in which these examples are used.\n",
            "\n",
            "#### 4. Applications of AI Agents\n",
            "- Explore various sectors where AI agents are implemented (e.g., healthcare, finance, customer service).\n",
            "- Highlight specific use cases and the impact of AI agents in these areas.\n",
            "\n",
            "#### 5. Differences Between AI Agents and Traditional Software\n",
            "- Compare and contrast AI agents with traditional software solutions.\n",
            "- Discuss the advantages that AI agents offer over conventional approaches.\n",
            "\n",
            "#### 6. Benefits of Using AI Agents\n",
            "- Outline the key benefits of integrating AI agents into business and technology processes.\n",
            "- Discuss efficiency, scalability, and enhanced decision-making.\n",
            "\n",
            "#### 7. AI Agent Technologies\n",
            "- Provide an overview of the technologies that enable AI agents (e.g., algorithms, data processing).\n",
            "- Discuss advancements in AI technologies that are shaping the future of AI agents.\n",
            "\n",
            "#### 8. Future of AI Agents\n",
            "- Speculate on future developments in AI agents and their potential impact on society and industries.\n",
            "- Discuss ethical considerations and challenges that may arise.\n",
            "\n",
            "#### Conclusion\n",
            "- Summarize the key points discussed in the article.\n",
            "- Encourage readers to explore further and stay informed about AI advancements.\n",
            "\n",
            "## 6. Important Notes\n",
            "- Ensure that the article is written in a clear, engaging, and informative tone.\n",
            "- Use subheadings and bullet points for better readability and to enhance user experience.\n",
            "- Incorporate relevant images, diagrams, or infographics to illustrate complex concepts where applicable.\n",
            "- Include links to credible sources for definitions, examples, and statistics to enhance the article's authority.\n",
            "- Optimize the article for SEO by naturally integrating the main and sub keywords throughout the text, particularly in headings and the introduction.\n",
            "- Aim for a word count of approximately 1,500 to 2,000 words to provide a thorough exploration of the topic.\n",
            "\n",
            "By following these instructions, the article will effectively address the search intent of users looking for information on AI agents while also being optimized for search engines.\n"
          ]
        }
      ]
    }
  ]
}